{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d2099bd",
   "metadata": {},
   "source": [
    "Code reference - https://www.kaggle.com/code/balraj98/context-encoder-gan-for-image-inpainting-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc21bdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagraagrawal/anaconda3/envs/newbase/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/kushagraagrawal/anaconda3/envs/newbase/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEENS6_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <955A2762-10C6-381C-99FA-06B93B8D6AED> /Users/kushagraagrawal/anaconda3/envs/newbase/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <6607DFFE-F5CB-30CC-8D45-014046A9CD96> /Users/kushagraagrawal/.local/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, math, sys\n",
    "import glob, itertools\n",
    "import argparse, random\n",
    "import sewar\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import vgg19\n",
    " \n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "random.seed(42)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1124406",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = sorted(list(os.listdir('StyleGAN.pytorch/ffhq')))[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ec132d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "allImages = []\n",
    "root = 'StyleGAN.pytorch/ffhq'\n",
    "for folder in folders:\n",
    "    allImages.extend(sorted(glob.glob(\"%s/%s/*.png\" %(root,folder))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e106529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allImages, _ = train_test_split(allImages, test_size=0.25, random_state=42) # training on 75% data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6b89ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImage, testImage = train_test_split(allImages, test_size=0.2, random_state=42)\n",
    "valImage, testImage = train_test_split(testImage, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6849533",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, files, transforms_=None, img_size=128, mask_size=64, mode=\"train\"):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.img_size = img_size\n",
    "        self.mask_size = mask_size\n",
    "        self.mode = mode\n",
    "        self.files = files\n",
    "        # for folder in folders:\n",
    "        #    self.files.extend(sorted(glob.glob(\"%s/%s/*.png\" %(root,folder))))\n",
    "        # self.files = self.files[:-4000] if mode == \"train\" else self.files[-4000:]\n",
    "\n",
    "    def apply_random_mask(self, img):\n",
    "        \"\"\"Randomly masks image\"\"\"\n",
    "        y1, x1 = np.random.randint(0, self.img_size - self.mask_size, 2)\n",
    "        y2, x2 = y1 + self.mask_size, x1 + self.mask_size\n",
    "        masked_part = img[:, y1:y2, x1:x2]\n",
    "        masked_img = img.clone()\n",
    "        masked_img[:, y1:y2, x1:x2] = 1\n",
    "\n",
    "        return masked_img, masked_part\n",
    "\n",
    "    def apply_center_mask(self, img):\n",
    "        \"\"\"Mask center part of image\"\"\"\n",
    "        # Get upper-left pixel coordinate\n",
    "        i = (self.img_size - self.mask_size) // 2\n",
    "        masked_img = img.clone()\n",
    "        masked_part = masked_img[:, i : i + self.mask_size, i : i + self.mask_size]\n",
    "        masked_img[:, i : i + self.mask_size, i : i + self.mask_size] = 1\n",
    "\n",
    "        return masked_img, masked_part, i\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img = Image.open(self.files[index % len(self.files)])\n",
    "        img = self.transform(img)\n",
    "        if(self.mode==\"train\"):\n",
    "            masked_img, aux = self.apply_random_mask(img)\n",
    "            return img, masked_img, aux\n",
    "        else:\n",
    "            masked_img, masked_part, i = self.apply_center_mask(img)\n",
    "            return img, masked_img, masked_part, i\n",
    "\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4a664b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_ = [\n",
    "    transforms.Resize((128, 128), Image.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]\n",
    "trainDL = DataLoader(\n",
    "    ImageDataset(files=trainImage, transforms_=transforms_, mode=\"train\"),\n",
    "    batch_size=12,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "valDL = DataLoader(\n",
    "    ImageDataset(files=valImage, transforms_=transforms_, mode=\"train\"),\n",
    "    batch_size=12,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "testDL = DataLoader(\n",
    "    ImageDataset(files=testImage, transforms_=transforms_, mode=\"test\"),\n",
    "    batch_size=12,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0219402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def downsample(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Conv2d(in_feat, out_feat, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm2d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "            return layers\n",
    "\n",
    "        def upsample(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.ConvTranspose2d(in_feat, out_feat, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm2d(out_feat, 0.8))\n",
    "            layers.append(nn.ReLU())\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *downsample(channels, 64, normalize=False),\n",
    "            *downsample(64, 64),\n",
    "            *downsample(64, 128),\n",
    "            *downsample(128, 256),\n",
    "            *downsample(256, 512),\n",
    "            nn.Conv2d(512, 4000, 1),\n",
    "            *upsample(4000, 512),\n",
    "            *upsample(512, 256),\n",
    "            *upsample(256, 128),\n",
    "            *upsample(128, 64),\n",
    "            nn.Conv2d(64, channels, 3, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, stride, normalize):\n",
    "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 3, stride, 1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        layers = []\n",
    "        in_filters = channels\n",
    "        for out_filters, stride, normalize in [(64, 2, False), (128, 2, True), (256, 2, True), (512, 1, True)]:\n",
    "            layers.extend(discriminator_block(in_filters, out_filters, stride, normalize))\n",
    "            in_filters = out_filters\n",
    "\n",
    "        layers.append(nn.Conv2d(out_filters, 1, 3, 1, 1))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07a89cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "# def save_sample(batches_done):\n",
    "    \n",
    "\n",
    "    \n",
    "# Loss function\n",
    "adversarial_loss = torch.nn.MSELoss()\n",
    "pixelwise_loss = torch.nn.L1Loss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator(channels=3)\n",
    "discriminator = Discriminator(channels=3)\n",
    "\n",
    "\n",
    "generator.cuda()\n",
    "discriminator.cuda()\n",
    "adversarial_loss.cuda()\n",
    "pixelwise_loss.cuda()\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3a4d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_h, patch_w = int(64 / 2 ** 3), int(64 / 2 ** 3)\n",
    "patch = (1, patch_h, patch_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94ca3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c5f31d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('saved_models/checkpoint_0.75_data.ckpt')\n",
    "generator.load_state_dict(checkpoint['generator'])\n",
    "discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "optimizer_G.load_state_dict(checkpoint['optimizer_G'])\n",
    "optimizer_D.load_state_dict(checkpoint['optimizer_D'])\n",
    "best_loss = checkpoint['loss']\n",
    "e = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "010e7cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e77a2c485540678474cd256b15c39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 0 :   0%|          | 0/3450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/kushagraagrawal/anaconda3/envs/newbase/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/kushagraagrawal/anaconda3/envs/newbase/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'ImageDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m gen_adv_loss, gen_pixel_loss, disc_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m tqdm_bar \u001b[38;5;241m=\u001b[39m tqdm(trainDL, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(trainDL)))\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (imgs, masked_imgs, masked_parts) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm_bar):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(imgs\u001b[38;5;241m.\u001b[39mshape, masked_imgs\u001b[38;5;241m.\u001b[39mshape, masked_parts\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Adversarial ground truths\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/newbase/lib/python3.8/site-packages/tqdm/notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/newbase/lib/python3.8/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:368\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:314\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:927\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    920\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m--> 927\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/anaconda3/envs/newbase/lib/python3.8/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/newbase/lib/python3.8/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/newbase/lib/python3.8/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/newbase/lib/python3.8/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/newbase/lib/python3.8/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/newbase/lib/python3.8/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gen_adv_losses, gen_pixel_losses, disc_losses, counter = [], [], [], []\n",
    "\n",
    "\n",
    "for epoch in range(e+1, 50):\n",
    "    \n",
    "    ### Training ###\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    gen_adv_loss, gen_pixel_loss, disc_loss = 0, 0, 0\n",
    "    tqdm_bar = tqdm(trainDL, desc=f'Training Epoch {epoch} ', total=int(len(trainDL)))\n",
    "    for i, (imgs, masked_imgs, masked_parts) in enumerate(tqdm_bar):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.shape[0], *patch).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.shape[0], *patch).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        imgs = Variable(imgs.type(Tensor))\n",
    "        masked_imgs = Variable(masked_imgs.type(Tensor))\n",
    "        masked_parts = Variable(masked_parts.type(Tensor))\n",
    "\n",
    "        ## Train Generator ##\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_parts = generator(masked_imgs)\n",
    "\n",
    "        # Adversarial and pixelwise loss\n",
    "        g_adv = adversarial_loss(discriminator(gen_parts), valid)\n",
    "        # print(gen_parts.shape, masked_parts.shape)\n",
    "        g_pixel = pixelwise_loss(gen_parts, masked_parts)\n",
    "        # Total loss\n",
    "        g_loss = 0.001 * g_adv + 0.999 * g_pixel\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        ## Train Discriminator ##\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(masked_parts), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_parts.detach()), fake)\n",
    "        d_loss = 0.5 * (real_loss + fake_loss)\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        gen_adv_loss, gen_pixel_loss, disc_loss\n",
    "        gen_adv_losses, gen_pixel_losses, disc_losses, counter\n",
    "        \n",
    "        gen_adv_loss += g_adv.item()\n",
    "        gen_pixel_loss += g_pixel.item()\n",
    "        gen_adv_losses.append(g_adv.item())\n",
    "        gen_pixel_losses.append(g_pixel.item())\n",
    "        disc_loss += d_loss.item()\n",
    "        disc_losses.append(d_loss.item())\n",
    "        counter.append(i*12 + imgs.size(0) + epoch*len(trainDL.dataset))\n",
    "        tqdm_bar.set_postfix(gen_adv_loss=gen_adv_loss/(i+1), gen_pixel_loss=gen_pixel_loss/(i+1), disc_loss=disc_loss/(i+1))\n",
    "        \n",
    "        # Generate sample at sample interval\n",
    "        batches_done = epoch * len(trainDL) + i\n",
    "#         if batches_done % 1000 == 0:\n",
    "#             save_sample(batches_done)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generator.eval()\n",
    "        discriminator.eval()\n",
    "        adv_val_loss, pixel_val_loss, disc_val_loss = 0, 0, 0\n",
    "        val_tqdm_bar = tqdm(valDL, desc=f'Val Epoch {epoch} ', total=int(len(valDL)))\n",
    "        for i, (imgs, masked_imgs, masked_parts) in enumerate(val_tqdm_bar):\n",
    "\n",
    "            # Adversarial ground truths\n",
    "            valid = Variable(Tensor(imgs.shape[0], *patch).fill_(1.0), requires_grad=False)\n",
    "            fake = Variable(Tensor(imgs.shape[0], *patch).fill_(0.0), requires_grad=False)\n",
    "\n",
    "            # Configure input\n",
    "            imgs = Variable(imgs.type(Tensor))\n",
    "            masked_imgs = Variable(masked_imgs.type(Tensor))\n",
    "            masked_parts = Variable(masked_parts.type(Tensor))\n",
    "\n",
    "            # Generate a batch of images\n",
    "            gen_parts = generator(masked_imgs)\n",
    "\n",
    "            # Adversarial and pixelwise loss\n",
    "            g_adv = adversarial_loss(discriminator(gen_parts), valid)\n",
    "            g_pixel = pixelwise_loss(gen_parts, masked_parts)\n",
    "            # Total loss\n",
    "            g_loss = 0.001 * g_adv + 0.999 * g_pixel\n",
    "\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "            real_loss = adversarial_loss(discriminator(masked_parts), valid)\n",
    "            fake_loss = adversarial_loss(discriminator(gen_parts.detach()), fake)\n",
    "            d_loss = 0.5 * (real_loss + fake_loss)\n",
    "\n",
    "        \n",
    "            adv_val_loss += g_adv.item()\n",
    "            pixel_val_loss += g_pixel.item()\n",
    "            disc_val_loss += d_loss.item()\n",
    "            val_tqdm_bar.set_postfix(adv_val_loss=adv_val_loss/(i+1), pixel_val_loss=pixel_val_loss/(i+1), disc_val_loss=disc_val_loss/(i+1))\n",
    "        print(\"Epoch: %d, val adv loss: %f, val pixel loss: %f, val disc loss: %f\"%(epoch, adv_val_loss, pixel_val_loss, disc_val_loss))\n",
    "\n",
    "        if((0.001 * adv_val_loss + 0.999 * pixel_val_loss) < best_loss):\n",
    "            best_loss = 0.001 * adv_val_loss + 0.999 * pixel_val_loss\n",
    "            PATH = 'saved_models/checkpoint_0.75_data.ckpt'\n",
    "            torch.save({\n",
    "                       'generator': generator.state_dict(),\n",
    "                       'discriminator': discriminator.state_dict(),\n",
    "                       'optimizer_G':optimizer_G.state_dict(),\n",
    "                       'optimizer_D':optimizer_D.state_dict(),\n",
    "                       'epoch': epoch,\n",
    "                       'loss': best_loss\n",
    "                       }, PATH)\n",
    "            # torch.save(generator.state_dict(), \"saved_models/generator.pth\")\n",
    "            # torch.save(discriminator.state_dict(), \"saved_models/discriminator.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10db480a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46837c218c444079bdc7c4ab5a4b16f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch 1 :   0%|          | 0/584 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psnr_score: 25.773566, ssim_score: 0.879482\n",
      "psnr_score: 25.377148, ssim_score: 0.874790\n",
      "psnr_score: 25.435174, ssim_score: 0.880449\n",
      "psnr_score: 24.378827, ssim_score: 0.862627\n",
      "psnr_score: 26.267398, ssim_score: 0.881934\n",
      "psnr_score: 25.207904, ssim_score: 0.881557\n",
      "psnr_score: 26.333401, ssim_score: 0.891545\n",
      "psnr_score: 24.858086, ssim_score: 0.876712\n",
      "psnr_score: 25.638654, ssim_score: 0.875017\n",
      "psnr_score: 24.545486, ssim_score: 0.869624\n",
      "psnr_score: 25.164248, ssim_score: 0.879841\n",
      "psnr_score: 26.072815, ssim_score: 0.888910\n",
      "psnr_score: 25.204582, ssim_score: 0.873574\n",
      "psnr_score: 24.860844, ssim_score: 0.876341\n",
      "psnr_score: 25.655674, ssim_score: 0.876466\n",
      "psnr_score: 24.571022, ssim_score: 0.873553\n",
      "psnr_score: 25.687770, ssim_score: 0.869561\n",
      "psnr_score: 24.185347, ssim_score: 0.861311\n",
      "psnr_score: 23.971751, ssim_score: 0.855961\n",
      "psnr_score: 24.023803, ssim_score: 0.864102\n",
      "psnr_score: 24.645585, ssim_score: 0.869901\n",
      "psnr_score: 24.857900, ssim_score: 0.877855\n",
      "psnr_score: 24.877574, ssim_score: 0.885839\n",
      "psnr_score: 24.707449, ssim_score: 0.871814\n",
      "psnr_score: 25.489324, ssim_score: 0.873730\n",
      "psnr_score: 25.154667, ssim_score: 0.878792\n",
      "psnr_score: 24.436420, ssim_score: 0.874014\n",
      "psnr_score: 24.584201, ssim_score: 0.871179\n",
      "psnr_score: 25.841602, ssim_score: 0.877541\n",
      "psnr_score: 26.380737, ssim_score: 0.883414\n",
      "psnr_score: 25.892454, ssim_score: 0.881117\n",
      "psnr_score: 23.826353, ssim_score: 0.868319\n",
      "psnr_score: 25.319393, ssim_score: 0.866279\n",
      "psnr_score: 24.679969, ssim_score: 0.866960\n",
      "psnr_score: 24.045653, ssim_score: 0.861470\n",
      "psnr_score: 24.619761, ssim_score: 0.872633\n",
      "psnr_score: 24.965359, ssim_score: 0.874189\n",
      "psnr_score: 25.108454, ssim_score: 0.872388\n",
      "psnr_score: 25.940145, ssim_score: 0.879643\n",
      "psnr_score: 25.539520, ssim_score: 0.867862\n",
      "psnr_score: 25.004587, ssim_score: 0.879976\n",
      "psnr_score: 24.324908, ssim_score: 0.870424\n",
      "psnr_score: 24.698570, ssim_score: 0.872186\n",
      "psnr_score: 24.499802, ssim_score: 0.860565\n",
      "psnr_score: 24.877338, ssim_score: 0.872265\n",
      "psnr_score: 24.552887, ssim_score: 0.875300\n",
      "psnr_score: 23.935548, ssim_score: 0.862007\n",
      "psnr_score: 23.292957, ssim_score: 0.864124\n",
      "psnr_score: 25.169115, ssim_score: 0.876331\n",
      "psnr_score: 24.748708, ssim_score: 0.867687\n",
      "psnr_score: 26.179734, ssim_score: 0.888294\n",
      "psnr_score: 24.077793, ssim_score: 0.859817\n",
      "psnr_score: 25.228184, ssim_score: 0.880270\n",
      "psnr_score: 24.301826, ssim_score: 0.867657\n",
      "psnr_score: 25.497056, ssim_score: 0.870104\n",
      "psnr_score: 24.403352, ssim_score: 0.865995\n",
      "psnr_score: 24.280636, ssim_score: 0.868465\n",
      "psnr_score: 25.601589, ssim_score: 0.874949\n",
      "psnr_score: 24.745461, ssim_score: 0.868724\n",
      "psnr_score: 25.251270, ssim_score: 0.868457\n",
      "psnr_score: 24.923127, ssim_score: 0.867477\n",
      "psnr_score: 25.336186, ssim_score: 0.871397\n",
      "psnr_score: 24.587815, ssim_score: 0.861464\n",
      "psnr_score: 25.859446, ssim_score: 0.873781\n",
      "psnr_score: 25.002310, ssim_score: 0.864129\n",
      "psnr_score: 25.179874, ssim_score: 0.874553\n",
      "psnr_score: 24.160095, ssim_score: 0.856987\n",
      "psnr_score: 25.403868, ssim_score: 0.870459\n",
      "psnr_score: 26.423501, ssim_score: 0.883697\n",
      "psnr_score: 24.020704, ssim_score: 0.860014\n",
      "psnr_score: 24.875416, ssim_score: 0.874614\n",
      "psnr_score: 23.439738, ssim_score: 0.852116\n",
      "psnr_score: 25.230682, ssim_score: 0.869373\n",
      "psnr_score: 25.740035, ssim_score: 0.877789\n",
      "psnr_score: 25.240331, ssim_score: 0.873732\n",
      "psnr_score: 26.041893, ssim_score: 0.867675\n",
      "psnr_score: 25.768607, ssim_score: 0.878699\n",
      "psnr_score: 25.827852, ssim_score: 0.880286\n",
      "psnr_score: 24.974399, ssim_score: 0.870442\n",
      "psnr_score: 25.270167, ssim_score: 0.865456\n",
      "psnr_score: 22.755641, ssim_score: 0.848368\n",
      "psnr_score: 24.679642, ssim_score: 0.861488\n",
      "psnr_score: 25.182560, ssim_score: 0.868625\n",
      "psnr_score: 25.467688, ssim_score: 0.876240\n",
      "psnr_score: 25.196593, ssim_score: 0.876170\n",
      "psnr_score: 24.840354, ssim_score: 0.880793\n",
      "psnr_score: 25.291050, ssim_score: 0.867750\n",
      "psnr_score: 25.049605, ssim_score: 0.861710\n",
      "psnr_score: 24.373878, ssim_score: 0.865864\n",
      "psnr_score: 24.914464, ssim_score: 0.874371\n",
      "psnr_score: 25.694237, ssim_score: 0.877111\n",
      "psnr_score: 24.489922, ssim_score: 0.870419\n",
      "psnr_score: 24.646499, ssim_score: 0.872912\n",
      "psnr_score: 25.191936, ssim_score: 0.869243\n",
      "psnr_score: 25.156693, ssim_score: 0.872968\n",
      "psnr_score: 26.120212, ssim_score: 0.894309\n",
      "psnr_score: 25.162071, ssim_score: 0.873419\n",
      "psnr_score: 25.047632, ssim_score: 0.877381\n",
      "psnr_score: 25.203288, ssim_score: 0.878241\n",
      "psnr_score: 24.498820, ssim_score: 0.856204\n",
      "psnr_score: 23.996378, ssim_score: 0.853328\n",
      "psnr_score: 24.208693, ssim_score: 0.863284\n",
      "psnr_score: 24.475157, ssim_score: 0.862767\n",
      "psnr_score: 24.778811, ssim_score: 0.860202\n",
      "psnr_score: 25.174465, ssim_score: 0.867225\n",
      "psnr_score: 24.457550, ssim_score: 0.864632\n",
      "psnr_score: 23.978732, ssim_score: 0.865300\n",
      "psnr_score: 24.941756, ssim_score: 0.874751\n",
      "psnr_score: 25.041524, ssim_score: 0.872330\n",
      "psnr_score: 25.136169, ssim_score: 0.868035\n",
      "psnr_score: 24.805089, ssim_score: 0.873586\n",
      "psnr_score: 25.689670, ssim_score: 0.875035\n",
      "psnr_score: 24.150648, ssim_score: 0.866566\n",
      "psnr_score: 25.550197, ssim_score: 0.881574\n",
      "psnr_score: 23.585737, ssim_score: 0.865626\n",
      "psnr_score: 25.763623, ssim_score: 0.872185\n",
      "psnr_score: 24.775576, ssim_score: 0.877879\n",
      "psnr_score: 26.065747, ssim_score: 0.878239\n",
      "psnr_score: 25.550665, ssim_score: 0.878796\n",
      "psnr_score: 25.073321, ssim_score: 0.883320\n",
      "psnr_score: 24.776813, ssim_score: 0.875540\n",
      "psnr_score: 25.463954, ssim_score: 0.863545\n",
      "psnr_score: 24.950819, ssim_score: 0.875704\n",
      "psnr_score: 25.618329, ssim_score: 0.867724\n",
      "psnr_score: 24.544059, ssim_score: 0.867477\n",
      "psnr_score: 25.042075, ssim_score: 0.873804\n",
      "psnr_score: 25.139772, ssim_score: 0.880995\n",
      "psnr_score: 25.530622, ssim_score: 0.880130\n",
      "psnr_score: 24.650842, ssim_score: 0.869600\n",
      "psnr_score: 25.105695, ssim_score: 0.879436\n",
      "psnr_score: 24.998144, ssim_score: 0.873198\n",
      "psnr_score: 25.448091, ssim_score: 0.880266\n",
      "psnr_score: 25.030542, ssim_score: 0.874049\n",
      "psnr_score: 24.345009, ssim_score: 0.866004\n",
      "psnr_score: 25.290658, ssim_score: 0.859036\n",
      "psnr_score: 24.405060, ssim_score: 0.865657\n",
      "psnr_score: 23.244020, ssim_score: 0.845338\n",
      "psnr_score: 26.553426, ssim_score: 0.890846\n",
      "psnr_score: 25.625950, ssim_score: 0.882958\n",
      "psnr_score: 24.209972, ssim_score: 0.858731\n",
      "psnr_score: 24.372754, ssim_score: 0.867669\n",
      "psnr_score: 25.261435, ssim_score: 0.882972\n",
      "psnr_score: 24.104623, ssim_score: 0.865628\n",
      "psnr_score: 24.330368, ssim_score: 0.871551\n",
      "psnr_score: 25.542091, ssim_score: 0.881383\n",
      "psnr_score: 26.195412, ssim_score: 0.881904\n",
      "psnr_score: 24.522432, ssim_score: 0.857583\n",
      "psnr_score: 25.353453, ssim_score: 0.872808\n",
      "psnr_score: 24.355331, ssim_score: 0.874442\n",
      "psnr_score: 26.021885, ssim_score: 0.886219\n",
      "psnr_score: 24.666141, ssim_score: 0.868501\n",
      "psnr_score: 24.914569, ssim_score: 0.870222\n",
      "psnr_score: 25.134596, ssim_score: 0.871533\n",
      "psnr_score: 24.021038, ssim_score: 0.861416\n",
      "psnr_score: 25.510986, ssim_score: 0.873634\n",
      "psnr_score: 25.203141, ssim_score: 0.873274\n",
      "psnr_score: 24.737959, ssim_score: 0.881985\n",
      "psnr_score: 24.564333, ssim_score: 0.870330\n",
      "psnr_score: 23.449001, ssim_score: 0.856643\n",
      "psnr_score: 25.180785, ssim_score: 0.867462\n",
      "psnr_score: 25.837523, ssim_score: 0.879809\n",
      "psnr_score: 26.061935, ssim_score: 0.872523\n",
      "psnr_score: 25.197332, ssim_score: 0.869954\n",
      "psnr_score: 25.131876, ssim_score: 0.868978\n",
      "psnr_score: 24.213184, ssim_score: 0.853028\n",
      "psnr_score: 24.326657, ssim_score: 0.861936\n",
      "psnr_score: 24.742440, ssim_score: 0.868330\n",
      "psnr_score: 24.450640, ssim_score: 0.869430\n",
      "psnr_score: 25.802640, ssim_score: 0.870117\n",
      "psnr_score: 24.005493, ssim_score: 0.861124\n",
      "psnr_score: 26.339390, ssim_score: 0.889620\n",
      "psnr_score: 24.739036, ssim_score: 0.882710\n",
      "psnr_score: 24.849070, ssim_score: 0.857654\n",
      "psnr_score: 25.111694, ssim_score: 0.872204\n",
      "psnr_score: 25.674569, ssim_score: 0.876895\n",
      "psnr_score: 25.114716, ssim_score: 0.874386\n",
      "psnr_score: 25.002907, ssim_score: 0.870480\n",
      "psnr_score: 24.988859, ssim_score: 0.869848\n",
      "psnr_score: 24.711257, ssim_score: 0.865765\n",
      "psnr_score: 25.492985, ssim_score: 0.887842\n",
      "psnr_score: 24.791315, ssim_score: 0.874086\n",
      "psnr_score: 24.258190, ssim_score: 0.858188\n",
      "psnr_score: 25.098624, ssim_score: 0.880011\n",
      "psnr_score: 23.807871, ssim_score: 0.860578\n",
      "psnr_score: 25.285196, ssim_score: 0.866113\n",
      "psnr_score: 24.749705, ssim_score: 0.875320\n",
      "psnr_score: 25.692624, ssim_score: 0.868457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psnr_score: 26.330039, ssim_score: 0.876460\n",
      "psnr_score: 25.947574, ssim_score: 0.872745\n",
      "psnr_score: 23.625593, ssim_score: 0.867077\n",
      "psnr_score: 26.361006, ssim_score: 0.882490\n",
      "psnr_score: 25.221725, ssim_score: 0.870087\n",
      "psnr_score: 24.809656, ssim_score: 0.873340\n",
      "psnr_score: 25.030916, ssim_score: 0.868861\n",
      "psnr_score: 25.465862, ssim_score: 0.868168\n",
      "psnr_score: 25.363409, ssim_score: 0.875014\n",
      "psnr_score: 25.186649, ssim_score: 0.884772\n",
      "psnr_score: 23.297334, ssim_score: 0.844888\n",
      "psnr_score: 25.306413, ssim_score: 0.870745\n",
      "psnr_score: 23.963944, ssim_score: 0.859380\n",
      "psnr_score: 24.196656, ssim_score: 0.861481\n",
      "psnr_score: 23.340527, ssim_score: 0.860390\n",
      "psnr_score: 26.176173, ssim_score: 0.879665\n",
      "psnr_score: 25.460982, ssim_score: 0.872411\n",
      "psnr_score: 24.406899, ssim_score: 0.880058\n",
      "psnr_score: 24.449274, ssim_score: 0.881711\n",
      "psnr_score: 25.199332, ssim_score: 0.867236\n",
      "psnr_score: 24.687757, ssim_score: 0.865710\n",
      "psnr_score: 25.595474, ssim_score: 0.875868\n",
      "psnr_score: 24.711742, ssim_score: 0.872498\n",
      "psnr_score: 24.414529, ssim_score: 0.872195\n",
      "psnr_score: 24.213612, ssim_score: 0.869201\n",
      "psnr_score: 24.477976, ssim_score: 0.861562\n",
      "psnr_score: 25.393232, ssim_score: 0.871812\n",
      "psnr_score: 24.684394, ssim_score: 0.872506\n",
      "psnr_score: 23.695755, ssim_score: 0.858947\n",
      "psnr_score: 25.010645, ssim_score: 0.873338\n",
      "psnr_score: 25.482840, ssim_score: 0.870400\n",
      "psnr_score: 24.564882, ssim_score: 0.867807\n",
      "psnr_score: 25.485953, ssim_score: 0.875630\n",
      "psnr_score: 24.050235, ssim_score: 0.859866\n",
      "psnr_score: 24.924752, ssim_score: 0.872734\n",
      "psnr_score: 25.036897, ssim_score: 0.861459\n",
      "psnr_score: 25.041170, ssim_score: 0.874752\n",
      "psnr_score: 26.645253, ssim_score: 0.902067\n",
      "psnr_score: 24.800150, ssim_score: 0.872552\n",
      "psnr_score: 25.855151, ssim_score: 0.873634\n",
      "psnr_score: 24.418862, ssim_score: 0.863117\n",
      "psnr_score: 24.199098, ssim_score: 0.868806\n",
      "psnr_score: 23.821953, ssim_score: 0.867070\n",
      "psnr_score: 23.757842, ssim_score: 0.865365\n",
      "psnr_score: 24.794916, ssim_score: 0.868086\n",
      "psnr_score: 25.333957, ssim_score: 0.880839\n",
      "psnr_score: 24.860539, ssim_score: 0.867375\n",
      "psnr_score: 25.383719, ssim_score: 0.872800\n",
      "psnr_score: 23.411480, ssim_score: 0.859182\n",
      "psnr_score: 24.598902, ssim_score: 0.871531\n",
      "psnr_score: 24.744284, ssim_score: 0.878384\n",
      "psnr_score: 24.259451, ssim_score: 0.867934\n",
      "psnr_score: 24.135657, ssim_score: 0.860014\n",
      "psnr_score: 25.020092, ssim_score: 0.872365\n",
      "psnr_score: 24.284098, ssim_score: 0.867269\n",
      "psnr_score: 26.353315, ssim_score: 0.881908\n",
      "psnr_score: 24.866490, ssim_score: 0.866036\n",
      "psnr_score: 25.538644, ssim_score: 0.879970\n",
      "psnr_score: 24.408779, ssim_score: 0.860263\n",
      "psnr_score: 25.772695, ssim_score: 0.885648\n",
      "psnr_score: 24.198203, ssim_score: 0.871732\n",
      "psnr_score: 25.014455, ssim_score: 0.872970\n",
      "psnr_score: 25.795847, ssim_score: 0.886582\n",
      "psnr_score: 26.029037, ssim_score: 0.867051\n",
      "psnr_score: 24.265798, ssim_score: 0.857159\n",
      "psnr_score: 25.105651, ssim_score: 0.873239\n",
      "psnr_score: 24.305965, ssim_score: 0.865614\n",
      "psnr_score: 24.295225, ssim_score: 0.878971\n",
      "psnr_score: 25.635082, ssim_score: 0.879936\n",
      "psnr_score: 25.678528, ssim_score: 0.876281\n",
      "psnr_score: 25.129745, ssim_score: 0.884397\n",
      "psnr_score: 25.140679, ssim_score: 0.872627\n",
      "psnr_score: 25.230980, ssim_score: 0.873618\n",
      "psnr_score: 25.091692, ssim_score: 0.875456\n",
      "psnr_score: 24.810846, ssim_score: 0.873301\n",
      "psnr_score: 25.597311, ssim_score: 0.881975\n",
      "psnr_score: 25.642503, ssim_score: 0.880359\n",
      "psnr_score: 24.876352, ssim_score: 0.873194\n",
      "psnr_score: 25.059837, ssim_score: 0.877946\n",
      "psnr_score: 23.807276, ssim_score: 0.871428\n",
      "psnr_score: 25.233499, ssim_score: 0.860820\n",
      "psnr_score: 24.885939, ssim_score: 0.864774\n",
      "psnr_score: 24.426378, ssim_score: 0.857783\n",
      "psnr_score: 25.838983, ssim_score: 0.887287\n",
      "psnr_score: 23.242396, ssim_score: 0.858370\n",
      "psnr_score: 25.832780, ssim_score: 0.882377\n",
      "psnr_score: 25.866817, ssim_score: 0.882763\n",
      "psnr_score: 25.109080, ssim_score: 0.870437\n",
      "psnr_score: 25.749123, ssim_score: 0.874294\n",
      "psnr_score: 25.372550, ssim_score: 0.869241\n",
      "psnr_score: 24.737260, ssim_score: 0.869149\n",
      "psnr_score: 24.483283, ssim_score: 0.870508\n",
      "psnr_score: 23.305071, ssim_score: 0.837266\n",
      "psnr_score: 24.126034, ssim_score: 0.855443\n",
      "psnr_score: 26.273464, ssim_score: 0.878331\n",
      "psnr_score: 24.331530, ssim_score: 0.868068\n",
      "psnr_score: 25.417035, ssim_score: 0.881791\n",
      "psnr_score: 24.254958, ssim_score: 0.878643\n",
      "psnr_score: 24.959664, ssim_score: 0.854101\n",
      "psnr_score: 25.559555, ssim_score: 0.875110\n",
      "psnr_score: 24.627333, ssim_score: 0.861679\n",
      "psnr_score: 26.078312, ssim_score: 0.884773\n",
      "psnr_score: 25.361747, ssim_score: 0.877275\n",
      "psnr_score: 25.921363, ssim_score: 0.883026\n",
      "psnr_score: 25.801392, ssim_score: 0.868164\n",
      "psnr_score: 25.001542, ssim_score: 0.873391\n",
      "psnr_score: 24.550917, ssim_score: 0.867918\n",
      "psnr_score: 23.671890, ssim_score: 0.852907\n",
      "psnr_score: 24.601750, ssim_score: 0.868530\n",
      "psnr_score: 23.730688, ssim_score: 0.868804\n",
      "psnr_score: 25.568949, ssim_score: 0.873483\n",
      "psnr_score: 23.997371, ssim_score: 0.864935\n",
      "psnr_score: 24.448339, ssim_score: 0.869563\n",
      "psnr_score: 22.859492, ssim_score: 0.844499\n",
      "psnr_score: 25.159191, ssim_score: 0.878266\n",
      "psnr_score: 25.334639, ssim_score: 0.879816\n",
      "psnr_score: 24.812510, ssim_score: 0.869294\n",
      "psnr_score: 25.297562, ssim_score: 0.868693\n",
      "psnr_score: 24.661830, ssim_score: 0.871397\n",
      "psnr_score: 25.192435, ssim_score: 0.866474\n",
      "psnr_score: 25.264086, ssim_score: 0.869555\n",
      "psnr_score: 24.150592, ssim_score: 0.860755\n",
      "psnr_score: 25.312848, ssim_score: 0.873589\n",
      "psnr_score: 25.340981, ssim_score: 0.875558\n",
      "psnr_score: 25.263736, ssim_score: 0.869542\n",
      "psnr_score: 24.849561, ssim_score: 0.863743\n",
      "psnr_score: 25.199103, ssim_score: 0.878023\n",
      "psnr_score: 25.463896, ssim_score: 0.870246\n",
      "psnr_score: 24.811003, ssim_score: 0.857517\n",
      "psnr_score: 25.360641, ssim_score: 0.879024\n",
      "psnr_score: 25.583046, ssim_score: 0.885643\n",
      "psnr_score: 24.784457, ssim_score: 0.876263\n",
      "psnr_score: 25.467049, ssim_score: 0.870863\n",
      "psnr_score: 24.428700, ssim_score: 0.868378\n",
      "psnr_score: 26.153620, ssim_score: 0.870331\n",
      "psnr_score: 24.401441, ssim_score: 0.860307\n",
      "psnr_score: 25.024880, ssim_score: 0.871138\n",
      "psnr_score: 25.356284, ssim_score: 0.876870\n",
      "psnr_score: 24.716354, ssim_score: 0.873691\n",
      "psnr_score: 24.931250, ssim_score: 0.875230\n",
      "psnr_score: 24.202829, ssim_score: 0.862284\n",
      "psnr_score: 25.683431, ssim_score: 0.896674\n",
      "psnr_score: 25.330498, ssim_score: 0.872250\n",
      "psnr_score: 25.125412, ssim_score: 0.869778\n",
      "psnr_score: 25.534555, ssim_score: 0.877281\n",
      "psnr_score: 24.862866, ssim_score: 0.873211\n",
      "psnr_score: 24.614996, ssim_score: 0.873033\n",
      "psnr_score: 25.850664, ssim_score: 0.873190\n",
      "psnr_score: 24.101647, ssim_score: 0.861650\n",
      "psnr_score: 24.723841, ssim_score: 0.873925\n",
      "psnr_score: 25.721473, ssim_score: 0.878762\n",
      "psnr_score: 24.214290, ssim_score: 0.866227\n",
      "psnr_score: 25.114454, ssim_score: 0.870324\n",
      "psnr_score: 23.626355, ssim_score: 0.859613\n",
      "psnr_score: 24.358023, ssim_score: 0.873944\n",
      "psnr_score: 24.909991, ssim_score: 0.875626\n",
      "psnr_score: 24.719149, ssim_score: 0.860242\n",
      "psnr_score: 23.955827, ssim_score: 0.857588\n",
      "psnr_score: 24.920054, ssim_score: 0.871000\n",
      "psnr_score: 25.001113, ssim_score: 0.872332\n",
      "psnr_score: 24.447521, ssim_score: 0.870728\n",
      "psnr_score: 24.854432, ssim_score: 0.860681\n",
      "psnr_score: 25.191317, ssim_score: 0.871993\n",
      "psnr_score: 24.321848, ssim_score: 0.864481\n",
      "psnr_score: 25.096536, ssim_score: 0.878305\n",
      "psnr_score: 25.891489, ssim_score: 0.882948\n",
      "psnr_score: 24.984848, ssim_score: 0.867557\n",
      "psnr_score: 24.571442, ssim_score: 0.865891\n",
      "psnr_score: 24.527533, ssim_score: 0.875009\n",
      "psnr_score: 24.760278, ssim_score: 0.852560\n",
      "psnr_score: 25.203112, ssim_score: 0.881937\n",
      "psnr_score: 25.047686, ssim_score: 0.880379\n",
      "psnr_score: 25.388550, ssim_score: 0.879271\n",
      "psnr_score: 24.039821, ssim_score: 0.859894\n",
      "psnr_score: 24.208850, ssim_score: 0.864465\n",
      "psnr_score: 25.063353, ssim_score: 0.869038\n",
      "psnr_score: 24.830990, ssim_score: 0.869979\n",
      "psnr_score: 24.597618, ssim_score: 0.870422\n",
      "psnr_score: 26.914898, ssim_score: 0.875137\n",
      "psnr_score: 24.902677, ssim_score: 0.874115\n",
      "psnr_score: 25.452345, ssim_score: 0.877368\n",
      "psnr_score: 25.521945, ssim_score: 0.884782\n",
      "psnr_score: 24.705562, ssim_score: 0.879016\n",
      "psnr_score: 23.127953, ssim_score: 0.841261\n",
      "psnr_score: 24.066087, ssim_score: 0.866949\n",
      "psnr_score: 25.226428, ssim_score: 0.879831\n",
      "psnr_score: 24.594588, ssim_score: 0.877004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psnr_score: 25.358484, ssim_score: 0.875778\n",
      "psnr_score: 25.511493, ssim_score: 0.872808\n",
      "psnr_score: 24.021179, ssim_score: 0.857626\n",
      "psnr_score: 24.605205, ssim_score: 0.881840\n",
      "psnr_score: 25.044654, ssim_score: 0.866119\n",
      "psnr_score: 25.118880, ssim_score: 0.869683\n",
      "psnr_score: 22.872596, ssim_score: 0.857620\n",
      "psnr_score: 25.055624, ssim_score: 0.863633\n",
      "psnr_score: 25.294164, ssim_score: 0.868477\n",
      "psnr_score: 23.373371, ssim_score: 0.845203\n",
      "psnr_score: 23.819467, ssim_score: 0.870052\n",
      "psnr_score: 25.348655, ssim_score: 0.869713\n",
      "psnr_score: 24.343320, ssim_score: 0.874778\n",
      "psnr_score: 25.506458, ssim_score: 0.878996\n",
      "psnr_score: 25.872450, ssim_score: 0.875548\n",
      "psnr_score: 25.144040, ssim_score: 0.888900\n",
      "psnr_score: 24.097496, ssim_score: 0.861122\n",
      "psnr_score: 25.064972, ssim_score: 0.877852\n",
      "psnr_score: 25.662737, ssim_score: 0.885109\n",
      "psnr_score: 24.903539, ssim_score: 0.861173\n",
      "psnr_score: 24.753197, ssim_score: 0.882566\n",
      "psnr_score: 25.598601, ssim_score: 0.870610\n",
      "psnr_score: 25.199219, ssim_score: 0.873661\n",
      "psnr_score: 26.459200, ssim_score: 0.885325\n",
      "psnr_score: 23.799351, ssim_score: 0.850250\n",
      "psnr_score: 23.254334, ssim_score: 0.851433\n",
      "psnr_score: 24.632709, ssim_score: 0.869595\n",
      "psnr_score: 24.477887, ssim_score: 0.867709\n",
      "psnr_score: 24.614371, ssim_score: 0.872499\n",
      "psnr_score: 25.101241, ssim_score: 0.861641\n",
      "psnr_score: 25.489609, ssim_score: 0.869562\n",
      "psnr_score: 25.204444, ssim_score: 0.884299\n",
      "psnr_score: 25.528164, ssim_score: 0.876609\n",
      "psnr_score: 24.363355, ssim_score: 0.865308\n",
      "psnr_score: 24.922063, ssim_score: 0.866841\n",
      "psnr_score: 23.853589, ssim_score: 0.865747\n",
      "psnr_score: 24.855985, ssim_score: 0.874755\n",
      "psnr_score: 25.227232, ssim_score: 0.865923\n",
      "psnr_score: 24.399068, ssim_score: 0.855047\n",
      "psnr_score: 25.363085, ssim_score: 0.870472\n",
      "psnr_score: 24.665293, ssim_score: 0.857669\n",
      "psnr_score: 25.388685, ssim_score: 0.875557\n",
      "psnr_score: 25.472028, ssim_score: 0.875855\n",
      "psnr_score: 25.025989, ssim_score: 0.879031\n",
      "psnr_score: 25.559726, ssim_score: 0.883566\n",
      "psnr_score: 25.154260, ssim_score: 0.865700\n",
      "psnr_score: 24.796371, ssim_score: 0.865998\n",
      "psnr_score: 24.058762, ssim_score: 0.866717\n",
      "psnr_score: 25.342001, ssim_score: 0.875579\n",
      "psnr_score: 25.290089, ssim_score: 0.880941\n",
      "psnr_score: 24.477793, ssim_score: 0.869305\n",
      "psnr_score: 25.529208, ssim_score: 0.875363\n",
      "psnr_score: 25.587884, ssim_score: 0.867092\n",
      "psnr_score: 24.161963, ssim_score: 0.870318\n",
      "psnr_score: 25.658234, ssim_score: 0.876406\n",
      "psnr_score: 24.588456, ssim_score: 0.863998\n",
      "psnr_score: 24.690982, ssim_score: 0.871096\n",
      "psnr_score: 26.159960, ssim_score: 0.878670\n",
      "psnr_score: 24.566867, ssim_score: 0.866770\n",
      "psnr_score: 25.236019, ssim_score: 0.873983\n",
      "psnr_score: 26.041117, ssim_score: 0.882798\n",
      "psnr_score: 24.887734, ssim_score: 0.869998\n",
      "psnr_score: 24.922992, ssim_score: 0.862522\n",
      "psnr_score: 26.198593, ssim_score: 0.877926\n",
      "psnr_score: 25.117341, ssim_score: 0.870292\n",
      "psnr_score: 23.902379, ssim_score: 0.862959\n",
      "psnr_score: 25.346103, ssim_score: 0.874849\n",
      "psnr_score: 24.803797, ssim_score: 0.869719\n",
      "psnr_score: 24.807594, ssim_score: 0.864939\n",
      "psnr_score: 24.080444, ssim_score: 0.865670\n",
      "psnr_score: 24.980630, ssim_score: 0.868432\n",
      "psnr_score: 25.006701, ssim_score: 0.867261\n",
      "psnr_score: 25.475111, ssim_score: 0.875598\n",
      "psnr_score: 25.187857, ssim_score: 0.876519\n",
      "psnr_score: 25.880980, ssim_score: 0.880599\n",
      "psnr_score: 25.095710, ssim_score: 0.877350\n",
      "psnr_score: 24.345028, ssim_score: 0.880857\n",
      "psnr_score: 26.050671, ssim_score: 0.880535\n",
      "psnr_score: 24.442326, ssim_score: 0.865235\n",
      "psnr_score: 24.915951, ssim_score: 0.867316\n",
      "psnr_score: 25.141020, ssim_score: 0.878575\n",
      "psnr_score: 26.053446, ssim_score: 0.871279\n",
      "psnr_score: 23.985196, ssim_score: 0.865054\n",
      "psnr_score: 24.533339, ssim_score: 0.862663\n",
      "psnr_score: 25.543947, ssim_score: 0.872288\n",
      "psnr_score: 25.920286, ssim_score: 0.867364\n",
      "psnr_score: 25.829863, ssim_score: 0.872693\n",
      "psnr_score: 24.032487, ssim_score: 0.857525\n",
      "psnr_score: 25.530840, ssim_score: 0.876208\n",
      "psnr_score: 25.551794, ssim_score: 0.873710\n",
      "psnr_score: 24.641071, ssim_score: 0.878182\n",
      "psnr_score: 25.006364, ssim_score: 0.872478\n",
      "psnr_score: 26.577533, ssim_score: 0.876853\n",
      "psnr_score: 25.760850, ssim_score: 0.884324\n",
      "psnr_score: 25.146042, ssim_score: 0.863691\n",
      "psnr_score: 25.100472, ssim_score: 0.871665\n",
      "psnr_score: 25.211364, ssim_score: 0.875839\n",
      "psnr_score: 25.120855, ssim_score: 0.881682\n",
      "psnr_score: 24.395330, ssim_score: 0.870842\n",
      "psnr_score: 25.945320, ssim_score: 0.883505\n",
      "psnr_score: 25.255747, ssim_score: 0.883683\n",
      "psnr_score: 26.004261, ssim_score: 0.877980\n",
      "psnr_score: 24.168532, ssim_score: 0.865341\n",
      "psnr_score: 25.118408, ssim_score: 0.875963\n",
      "psnr_score: 24.713428, ssim_score: 0.868153\n",
      "psnr_score: 25.189434, ssim_score: 0.867700\n",
      "psnr_score: 25.281230, ssim_score: 0.877980\n",
      "psnr_score: 24.640671, ssim_score: 0.868743\n",
      "psnr_score: 25.614184, ssim_score: 0.874036\n",
      "psnr_score: 24.941852, ssim_score: 0.869584\n",
      "psnr_score: 25.278020, ssim_score: 0.869952\n",
      "psnr_score: 26.236887, ssim_score: 0.887404\n",
      "psnr_score: 24.234685, ssim_score: 0.857098\n",
      "psnr_score: 24.731138, ssim_score: 0.875329\n",
      "psnr_score: 25.621843, ssim_score: 0.885922\n",
      "psnr_score: 23.702739, ssim_score: 0.860772\n",
      "psnr_score: 24.646725, ssim_score: 0.870339\n",
      "psnr_score: 23.796207, ssim_score: 0.857918\n",
      "psnr_score: 24.438442, ssim_score: 0.871925\n",
      "psnr_score: 24.821431, ssim_score: 0.873366\n",
      "psnr_score: 24.981246, ssim_score: 0.863237\n",
      "psnr_score: 23.895447, ssim_score: 0.864303\n",
      "psnr_score: 24.582325, ssim_score: 0.865084\n",
      "psnr_score: 24.617511, ssim_score: 0.875539\n",
      "psnr_score: 22.901327, ssim_score: 0.850049\n",
      "psnr_score: 25.680907, ssim_score: 0.879031\n",
      "psnr_score: 23.886469, ssim_score: 0.859346\n",
      "psnr_score: 26.094764, ssim_score: 0.888910\n",
      "psnr_score: 25.572948, ssim_score: 0.878290\n",
      "psnr_score: 24.213872, ssim_score: 0.854792\n",
      "psnr_score: 24.956624, ssim_score: 0.873224\n",
      "psnr_score: 24.892181, ssim_score: 0.857638\n",
      "psnr_score: 25.066098, ssim_score: 0.869235\n",
      "psnr_score: 24.584172, ssim_score: 0.862555\n",
      "psnr_score: 25.069197, ssim_score: 0.880285\n",
      "psnr_score: 26.178992, ssim_score: 0.882492\n",
      "psnr_score: 24.478721, ssim_score: 0.880833\n",
      "psnr_score: 25.079981, ssim_score: 0.872035\n",
      "psnr_score: 24.839379, ssim_score: 0.865347\n",
      "psnr_score: 26.180900, ssim_score: 0.868838\n",
      "psnr_score: 25.126014, ssim_score: 0.861537\n",
      "psnr_score: 25.678529, ssim_score: 0.872751\n",
      "psnr_score: 25.568699, ssim_score: 0.880274\n",
      "psnr_score: 25.207747, ssim_score: 0.867557\n",
      "psnr_score: 25.379793, ssim_score: 0.865376\n",
      "psnr_score: 24.135429, ssim_score: 0.861899\n",
      "psnr_score: 25.111809, ssim_score: 0.870619\n",
      "psnr_score: 24.429892, ssim_score: 0.863783\n",
      "psnr_score: 25.106383, ssim_score: 0.872905\n",
      "psnr_score: 24.883368, ssim_score: 0.872627\n",
      "psnr_score: 25.633203, ssim_score: 0.881512\n",
      "psnr_score: 25.616338, ssim_score: 0.874193\n",
      "psnr_score: 25.546177, ssim_score: 0.878117\n",
      "psnr_score: 23.741293, ssim_score: 0.871281\n",
      "psnr_score: 23.744545, ssim_score: 0.860945\n",
      "psnr_score: 25.498874, ssim_score: 0.874760\n",
      "psnr_score: 25.402036, ssim_score: 0.870442\n",
      "psnr_score: 25.284542, ssim_score: 0.881272\n",
      "psnr_score: 24.233042, ssim_score: 0.864943\n",
      "psnr_score: 24.425676, ssim_score: 0.877455\n",
      "psnr_score: 25.351742, ssim_score: 0.861460\n",
      "psnr_score: 25.607503, ssim_score: 0.877896\n",
      "psnr_score: 24.334055, ssim_score: 0.869837\n",
      "psnr_score: 24.032776, ssim_score: 0.859677\n",
      "psnr_score: 24.699859, ssim_score: 0.868058\n",
      "psnr_score: 25.566557, ssim_score: 0.866289\n",
      "psnr_score: 25.442570, ssim_score: 0.870619\n",
      "psnr_score: 25.051082, ssim_score: 0.862331\n",
      "psnr_score: 24.377221, ssim_score: 0.870283\n",
      "psnr_score: 24.964805, ssim_score: 0.870722\n",
      "psnr_score: 24.489772, ssim_score: 0.872893\n",
      "psnr_score: 25.160061, ssim_score: 0.874270\n",
      "psnr_score: 24.915286, ssim_score: 0.878293\n",
      "psnr_score: 24.086990, ssim_score: 0.852843\n",
      "psnr_score: 23.703322, ssim_score: 0.860537\n",
      "psnr_score: 24.759333, ssim_score: 0.866062\n",
      "psnr_score: 25.776594, ssim_score: 0.869539\n",
      "psnr_score: 23.643966, ssim_score: 0.856936\n",
      "psnr_score: 24.577279, ssim_score: 0.865923\n",
      "psnr_score: 24.835202, ssim_score: 0.864613\n",
      "psnr_score: 24.136701, ssim_score: 0.872881\n",
      "psnr_score: 25.291551, ssim_score: 0.882323\n",
      "psnr_score: 25.457298, ssim_score: 0.875825\n",
      "psnr_score: 24.767877, ssim_score: 0.871853\n",
      "psnr_score: 25.389793, ssim_score: 0.872789\n",
      "psnr_score: 25.182969, ssim_score: 0.873667\n",
      "psnr_score: 24.768880, ssim_score: 0.870873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psnr_score: 24.755054, ssim_score: 0.869547\n",
      "psnr_score: 24.890571, ssim_score: 0.870262\n",
      "psnr_score: 23.687698, ssim_score: 0.866114\n",
      "psnr_score: 24.053134, ssim_score: 0.864823\n",
      "psnr_score: 25.246977, ssim_score: 0.878193\n",
      "psnr_score: 24.539676, ssim_score: 0.864724\n",
      "psnr_score: 24.937000, ssim_score: 0.875284\n",
      "psnr_score: 26.062562, ssim_score: 0.883664\n",
      "psnr_score: 25.200018, ssim_score: 0.868201\n",
      "psnr_score: 24.391823, ssim_score: 0.858853\n",
      "psnr_score: 24.713842, ssim_score: 0.867012\n",
      "psnr_score: 25.297549, ssim_score: 0.868810\n",
      "psnr_score: 25.544650, ssim_score: 0.880071\n",
      "psnr_score: 24.472348, ssim_score: 0.872732\n",
      "psnr_score: 25.268668, ssim_score: 0.871984\n",
      "psnr_score: 25.348591, ssim_score: 0.881878\n",
      "psnr_score: 24.688783, ssim_score: 0.881149\n",
      "psnr_score: 23.738825, ssim_score: 0.865069\n",
      "psnr_score: 25.664326, ssim_score: 0.881375\n",
      "psnr_score: 23.975125, ssim_score: 0.859770\n",
      "psnr_score: 24.835357, ssim_score: 0.868103\n",
      "psnr_score: 25.359298, ssim_score: 0.891104\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for dimension 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_637/691379320.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mssim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilled_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# print(pred.shape, gt.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for dimension 0 with size 4"
     ]
    }
   ],
   "source": [
    "# Load best model\n",
    "import cv2\n",
    "def normalize_img(img):\n",
    "    norm_image = cv2.normalize(img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    norm_image = norm_image.astype(np.uint8)\n",
    "    return norm_image\n",
    "\n",
    "with torch.no_grad():\n",
    "    checkpoint = torch.load('saved_models/checkpoint_0.75_data.ckpt')\n",
    "    generator.load_state_dict(checkpoint['generator'])\n",
    "    discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "\n",
    "    test_tqdm_bar = tqdm(testDL, desc=f'Test Epoch 1 ', total=int(len(testDL)))\n",
    "    pixel_test_loss = 0\n",
    "    for step, (imgs, masked_imgs, masked_parts, i) in enumerate(test_tqdm_bar):\n",
    "\n",
    "#     samples, masked_samples, i = next(iter(testDL))\n",
    "        samples = Variable(imgs.type(Tensor))\n",
    "        masked_samples = Variable(masked_imgs.type(Tensor))\n",
    "        masked_parts = Variable(masked_parts.type(Tensor))\n",
    "        i = i[0].item()  # Upper-left coordinate of mask\n",
    "        # Generate inpainted image\n",
    "        gen_mask = generator(masked_samples)\n",
    "    \n",
    "        g_pixel = pixelwise_loss(gen_mask, masked_parts)\n",
    "        # print(gen_mask.shape, coords)\n",
    "        filled_samples = masked_samples.clone()\n",
    "        filled_samples[:, :, i : i + 64, i : i + 64] = gen_mask\n",
    "        # Save sample\n",
    "        sample = torch.cat((masked_samples.data, filled_samples.data, samples.data), -2)\n",
    "        psnr = 0\n",
    "        ssim = 0\n",
    "        for i in range(12):\n",
    "            pred = normalize_img(filled_samples[i].permute(1,2,0).cpu().numpy())\n",
    "            gt = normalize_img(samples[i].permute(1,2,0).cpu().numpy())\n",
    "            # print(pred.shape, gt.shape)\n",
    "            psnr_score = sewar.psnr(pred,gt)\n",
    "            # print(psnr_score)\n",
    "            #ssim\n",
    "            ssim_score = sewar.ssim(pred,gt)[0]\n",
    "            psnr += psnr_score\n",
    "            ssim += ssim_score\n",
    "        print(\"psnr_score: %f, ssim_score: %f\"%(psnr/12, ssim/12))\n",
    "        pixel_test_loss += g_pixel.item()\n",
    "        if(step % 100 == 0):\n",
    "            save_image(sample, \"images/%d_75.png\" % step, nrow=6, normalize=True)\n",
    "    print(\"final pixel loss: {:.4f}\".format(pixel_test_loss/int(len(testDL))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a533ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
